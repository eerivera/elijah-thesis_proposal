\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{setspace}
\doublespacing

\begin{document}

\begin{titlepage}
   \begin{center}
       \vspace*{1cm}
       Massachusetts Institute of Technology \\
       Department of Electrical Engineering and Computer Science
 
       \vspace{1cm}
       Proposal for Thesis Research in Partial Fulfillment \\
       of the Requirements for the Degree of \\
       Master of Engineering in Electrical Engineering and Computer Science
 
       \vspace{1cm}
 
       Formal Verification of Safety Guarantees for Unsafe Code in a Rust-based Operating System
 
       \vspace{1cm}
       Elijah Rivera \\
       December 2019
 
       \vspace{1cm}
        Supervisor: Professor Howard Shrobe
   \end{center}
\end{titlepage}

\section{Abstract}
%TODO

%TODO - figure out how to format the word "unsafe"

\section{Introduction}

%NHB: these are what rustbelt actually addresses. For your proposal lets thing
%big: extensions to the rustbelt proofs -- is this actually
%the desirable set of things to verify?? What would an ideal set of proofs be?
%You can sketch out a bigger problem than we'll have time to solve -- but
%thinking about how to push further than Rustbelt is invaluable.
Memory errors in programs have been a major source of errors and exploitable vulnerabilities for a long time. Microsoft recently did a study where they found that in the past decade, memory errors have comprised $\sim70\%$ of discovered vulnerabilities in their products. %TODO - quote stat here https://github.com/microsoft/MSRC-Security-Research/blob/master/presentations/2019_02_BlueHatIL/2019_01%20-%20BlueHatIL%20-%20Trends%2C%20challenge%2C%20and%20shifts%20in%20software%20vulnerability%20mitigation.pdf
These errors include explicit corruption of the stack or heap of a program, accessing memory after it has been deallocated/freed (also known as use-after-free), accessing memory before it has been initialized, accessing memory that is "out of bounds" (including the null address), and treating memory with a certain type as if it has a different type.

Concurrent programs also have additional opportunities for errors with data races, where a timing or scheduling difference could affect the final result of a program. These errors occur when two or more threads have access to the same memory location and at least one of the threads is writing to that memory without using a proper locking discipline. %TODO - quote data race paper?

Reasoning about these errors is difficult. Tools continue to be developed which help in detecting/mitigating these errors, but we still continue to see memory errors and data races in software systems of every scale. We also see how these errors can be exploited into large vulnerabilities. %TODO - give examples here?

\subsection{Rust}
The programming language Rust has recently seen increased usage in the computer systems community because it claims to statically prevent many of above errors. Specifically, the developers claim that ``Rust guarantees memory safety and data-race freedom." % TODO - quote https://doc.rust-lang.org/1.0.0/style/safety/README.html.
``If all you do is write Safe Rust, you will never have to worry about type-safety or memory-safety. You will never endure a dangling pointer, a use-after-free, or any other kind of Undefined Behavior."
% TODO - quote https://doc.rust-lang.org/nomicon/meet-safe-and-unsafe.html
Rust's ability to make these claims relies on its novel approach to memory safety as type safety, using an ownership system. By encoding information about the kinds of reference to an object or the lifetime of the object into the type system, Rust is able to utilize existing compiler techniques to statically ensure that programs that compile meet the memory-safety guarantees above.

\subsection{Unsafe Rust}
However, many low-level systems have operations that would break these compiler restrictions. The rest of this paper will be from the context of operating systems. In operating systems, some of the operations that must necessarily break these restrictions include memory-mapped I/O operations, inlined sections of assembly code, and direct pointer arithmetic and related instructions. These operations are prevented by different type-checker restrictions and therefore do not compile. For this reason, Rust provides a backdoor in the form of the keyword "unsafe".

In Rust, "unsafe" signals to the compiler that the programmer is writing code that he/she knows will not pass the Rust type-checker. The burden of verifying that the code adheres to memory-safety and type-safety falls back onto the programmer. This means that code that includes a dependence on "unsafe" ultimately has the same level of guarantee as pre-Rust solutions: "hopefully the programmer is correct."

Unfortunately, this backdoor doesn't just undermine the guarantees of code that contains "unsafe" section inserted by the programmer. Many of the Rust standard library data structures also contain some amount of "unsafe" code. Any code that relies on these data structures also now has a similar lack of the earlier formal guarantees. Now even though we started with a language that is statically safe, even using the standard libraries can potentially violate this safety.

%NHB: this is the "state-of-the-art" section of your intro. Highlight the
%contributions they made, but also show the remaining gaps. You've identified
%and motivated a problem by, show that the state-of-the-art doesn't solve it.
\subsection{RustBelt}
In fact, even making the claim that Rust without "unsafe" (Safe Rust, as designated by the Rust community) is statically safe is still a claim without proof. The RustBelt project has made significant progress in this domain so far. RustBelt is a collection of machine-checked proofs in Coq that formalizes a large subset of Rust and proves that its semantics are correct.

It then goes further, and provides a method for proving correctness for new libraries which depend on "unsafe" code. It uses this method to verify correctness for a large portion of the standard libraries. This enables us to once again confidently make strong claims about the type-safety and memory-safety of Rust.

But this confidence is limited. These proofs still only apply to programs written in Safe Rust whose dependencies are limited to the standard libraries checked by RustBelt. In the world of operating systems, this is simply not enough.
%NHB: can we extend the rustbelt proofs to new properties? Can we extend them
%(or perhaps a subset) to constructs that Rustbelt can't currently handle? What
%are the boundaries of Rustbelt, and how can we push them out.
\subsection{Our contribution}
In this project, our goal is to extend the confident guarantees of Safe Rust to low-level systems programming paradigms. We will take an operating system written in Rust as an example, categorize patterns of necessary usage for "unsafe" code, and attempt to statically verify that this usage still adheres to the safety guarantees of Rust mentioned previously. 

Depending on the patterns encountered, the needs of this guarantee may differ. For many of the internal data structures we expect the process to look similar to the extensible approach taken by RustBelt, while we expect new approaches to be necessary for other patterns of "unsafe" usage.

One of the first ways to increase confidence in the code is to decrease the number of places where "unsafe" is used. Thus, before attempting to make claims about necessary "unsafe" code, we will attempt to isolate and reduce the usages of "unsafe" where possible.

%NHB: Side note: it's okay to have a master thesis that focuses this much on
%rustbelt.  for a conference paper you'd want to be more agressive about
%claiming new ground and showing additional contributions (vice extensions) to
%rustbelt. Guard against this becoming an ode to rustbelt, or excessively focued
%on what they've done instead of what you've done.

\section{Background}
\subsection{Safety of Rust}
Rust's approach to memory safety involves the use of an extensive ownership system integrated into its type system. In this system, variable bindings "have ownership" of the data they're bound to. %TODO - https://doc.rust-lang.org/1.9.0/book/ownership.html
For this reason, Rust also prevents more than one variable from being bound to a piece of data. Reassignment is processed with move or copy semantics, instead of aliasing as in many other programming languages.
%TODO - should I include an example here.

Rust also has the notion of "borrowing", which creates a reference to something without taking ownership of it. There are both mutable and immutable borrows, and the type system enforces that you do not have more than one reference to a piece of data when one of those references is mutable. This enables the type system to statically check for and prevent data races at compile time.

A reference also has an associated lifetime marked in the type system. The lifetime of the reference is never allowed to exceed the lifetime of the variable binding itself. This prevents "use-after-free" errors.

These ownership rules are formalized in the RustBelt system and proven correct for its formalization of Safe Rust. However, they are not guaranteed to hold in places where "unsafe" is used. RustBelt attempts to reason about these sections of code with the ideas of syntactic and semantic correctness.

\subsection{Syntactic and Semantic correctness}
Most systems programmers are not trying to write incorrect code. The programmer has some sort of internal intuitive argument for why their code is correct and type-safe, even though the compiler may disagree.

One canonical example of this is interior mutability, or the idea of mutation through a shared reference. This is explicitly forbidden by the ownership rules above, which say that if I have a mutable reference I can't have more than one reference. However, this functionality is still available in Rust, through a standard library construct called Cell.
%TODO - should I expand on Cell more here?

By necessity, Cell is implemented in Rust using the "unsafe" keyword. However, the RustBelt project was still able to prove that its API adhered to the restrictions of Safe Rust. That is, through careful restrictions of "unsafe" usage, the code still behaves like safe code (semantic correctness), even though it doesn't adhere to the strict rules of the type-checker (syntactic correctness).

\subsection{RustBelt for Unsafe Rust}
RustBelt provides a way to specify what must be proved in order to confirm that a library API actually does constitute a sound extension of Rust's type system. Given a description of the API, it will generate obligations that the user must prove hold before they can say that the described API is safe to use.

There is also included machinery for determining that implementations of the API actually adhere to the typing specifications provided, and examples of this in the proofs of the standard libraries.

\subsection{Why RustBelt fails us}
This approach to securing Rust works well when all "unsafe" operations can be tightly encapsulated by data structures with safe APIs. There are a number of these in our operating system project as well, and all of these data structures should be able to be proven semantically correct with minor addition to the RustBelt framework.

However, this only covers one type of "unsafe" usage in operating system code, and is not enough for many other paradigms. Both inlined assembly code and memory-mapped I/O operations directly access and modify memory addresses, which Rust's ownership type system cannot reason about. As RustBelt only serves to prove the guarantees of Rust's type system, it will be unable to make any safety guarantees about these types of "unsafe" code. We want to be able to guarantee the safety of the entire operating system, including these sections of code, and so additional methods, formalizations and proofs will be necessary.

%NHB: be sure to highight uses of unsafe by OS, and why they differ from user
%space code that RustBelt focused on.

\section{Proposed work}
%NHB: emphasize that OS code has unique requirements for unsafe that need to be
%addressed
The first part of the project will be to locate and isolate instances of "unsafe" in a Rust-based operating system called Tock, with the goal of either eliminating the need for "unsafe" entirely or at least shrinking it to the smallest possible size. 

We have already found success with this. As a preliminary exploration, we attempted to rewrite one of the core data structures in Tock with only safe code and were successful. We expect to be able to further reduce or eliminate "unsafe code" in other similar data structures in the near future.

As we encounter these irreducible blocks of "unsafe" code, we will document and categorize them. We hope to see duplicated patterns that allow us to factor out many "unsafe" uses into shared libraries with safe APIs, which would allow us to leverage the RustBelt machinery to prove these pieces correct.

We fully expect to encounter paradigms of "unsafe" use that do not fall into the previous categories of reduction or abstraction. In these cases, we hope to at least be able to isolate the unsafe code, and write proofs (maybe handwritten but preferably machine-checked) about the correctness of such sections.


%NHB: highlight things that come out of this case study for differences with
%rustbelt / new things for OS code.

\section{Timeline}
%TODO - ???

\section{Alternative approaches}
This is not the only way we could approach adding safety to an operating system. Here we will discuss other approaches that have been taken and the trade-offs they have.

\subsection{Improved static checking}
    \begin{itemize}
        \item More complicated static checking drastically increases runtime which decreases usability.
        \item Current systems can't automatically reason about certain things
    \end{itemize}
    
\subsection{Software testing}
    
\subsection{Problem detection/mitigation}
    
\subsection{Alex's project}

\section{Summary}
% TODO

\section{References}
% TODO - figure out how to bibliography in LaTeX

\end{document}
